# this is set up for doing the data ingestion

# URLs and such that are needed can be defined here

# when read, this is a dictionary, but then the read_yaml function converts it to a ConfigBox


artifacts_roots: artifacts
# this defines the artifacts directory where my components and such will be stored

# apaprently, the samsumdata.zip will be downloaded from the github repo and stored, into "data.zip" defined below
data_ingestion:
  root_dir: artifacts/data_ingestion
  source_URL: https://github.com/SoogeunParkValcon/Datasets/raw/main/samsumdata.zip
  local_data_file: artifacts/data_ingestion/data.zip
  unzip_dir: artifacts/data_ingestion

data_validation:
  root_dir: artifacts/data_validation
  STATUS_FILE: artifacts/data_validation/status.txt
  ALL_REQUIRED_FILES: ["train", "test", "validation"]
# so the goal is:
# 1. create artifacts/data_validation directory
# 2. check whether the required files: train, test, validation are all available
# 3. return the results in the status.txt file

data_transformation:
  root_dir: artifacts/data_transformation
  data_path: artifacts/data_ingestion/samsum_dataset
  result_file_name: samsumdata_transformed
  tokenizer_name: mrm8488/t5-base-finetuned-summarize-news
# 1. directory created 
# 2. data read from artifacts/data_ingestion/samsum_dataset
# 3. data transformed using the tokenizer
# 4. data saved in artifacts/data_transformation/samsumdata_transformedâˆ‘

model_trainer:
  root_dir: artifacts/model_trainer
  data_path: artifacts/data_transformation/samsumdata_transformed
  model_ckpt: mrm8488/t5-base-finetuned-summarize-news

